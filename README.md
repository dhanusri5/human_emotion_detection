
# Human Emotion Detection (Image + Audio + Multimodal)

This project detects human emotions using:
- Facial expressions (image)
- Voice tone (audio)
- Combined multimodal model

## Project Flow
1. Preprocess audio & image datasets  
2. Train individual models  
3. Extract embeddings  
4. Build the multimodal fusion model  
5. Serve results with FastAPI backend  
6. Simple HTML UI for user interaction  

## Folder Structure
Refer to the `/src` and `/notebooks` folders for model training and experiments.


